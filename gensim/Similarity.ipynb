{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity\n",
    "In this tutorial we determine similarity between pairs of documents, or the similarity between a specific document and a set of other documents (such as a user query vs. indexed documents)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matteo.Cuccato\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:855: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "2017-02-06 16:50:50,265 : INFO : 'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-06 16:55:58,782 : INFO : loading Dictionary object from /tmp/deerwester.dict\n",
      "2017-02-06 16:55:58,784 : INFO : loaded /tmp/deerwester.dict\n",
      "2017-02-06 16:55:58,785 : INFO : loaded corpus index from /tmp/deerwester.mm.index\n",
      "2017-02-06 16:55:58,786 : INFO : initializing corpus reader from /tmp/deerwester.mm\n",
      "2017-02-06 16:55:58,787 : INFO : accepted corpus with 9 documents, 12 features, 28 non-zero entries\n"
     ]
    }
   ],
   "source": [
    "# load dictionary and corpus\n",
    "dictionary = corpora.Dictionary.load('/tmp/deerwester.dict')\n",
    "corpus = corpora.MmCorpus('/tmp/deerwester.mm') # comes from the first tutorial, \"From strings to vectors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-06 16:56:23,464 : INFO : using serial LSI version on this node\n",
      "2017-02-06 16:56:23,465 : INFO : updating model with new documents\n",
      "2017-02-06 16:56:23,467 : INFO : preparing a new chunk of documents\n",
      "2017-02-06 16:56:23,468 : INFO : using 100 extra samples and 2 power iterations\n",
      "2017-02-06 16:56:23,469 : INFO : 1st phase: constructing (12, 102) action matrix\n",
      "2017-02-06 16:56:23,471 : INFO : orthonormalizing (12, 102) action matrix\n",
      "2017-02-06 16:56:23,475 : INFO : 2nd phase: running dense svd on (12, 9) matrix\n",
      "2017-02-06 16:56:23,477 : INFO : computing the final decomposition\n",
      "2017-02-06 16:56:23,478 : INFO : keeping 2 factors (discarding 43.156% of energy spectrum)\n",
      "2017-02-06 16:56:23,479 : INFO : processed documents up to #9\n",
      "2017-02-06 16:56:23,481 : INFO : topic #0(3.341): 0.644*\"system\" + 0.404*\"user\" + 0.301*\"eps\" + 0.265*\"time\" + 0.265*\"response\" + 0.240*\"computer\" + 0.221*\"human\" + 0.206*\"survey\" + 0.198*\"interface\" + 0.036*\"graph\"\n",
      "2017-02-06 16:56:23,482 : INFO : topic #1(2.542): 0.623*\"graph\" + 0.490*\"trees\" + 0.451*\"minors\" + 0.274*\"survey\" + -0.167*\"system\" + -0.141*\"eps\" + -0.113*\"human\" + 0.107*\"response\" + 0.107*\"time\" + -0.072*\"interface\"\n"
     ]
    }
   ],
   "source": [
    "# initialize lsi with corpus and dictionary\n",
    "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose a user typed in the query “Human computer interaction”. We would like to sort our nine corpus documents in decreasing order of relevance to this query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.46182100453271574), (1, -0.070027665278999993)]\n"
     ]
    }
   ],
   "source": [
    "doc = \"Human computer interaction\"\n",
    "vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "vec_lsi = lsi[vec_bow] # convert the query to LSI space\n",
    "print(vec_lsi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare for similarity queries, we need to enter all documents which we want to compare against subsequent queries. In our case, they are the same nine documents used for training LSI, converted to 2-D LSA space. But that’s only incidental, we might also be indexing a different corpus altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-06 17:03:54,499 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n",
      "2017-02-06 17:03:54,502 : INFO : creating matrix with 9 documents and 2 features\n",
      "2017-02-06 17:03:54,505 : INFO : saving MatrixSimilarity object under /tmp/deerwester.index, separately None\n",
      "2017-02-06 17:03:54,507 : INFO : saved /tmp/deerwester.index\n",
      "2017-02-06 17:03:54,508 : INFO : loading MatrixSimilarity object from /tmp/deerwester.index\n",
      "2017-02-06 17:03:54,509 : INFO : loaded /tmp/deerwester.index\n"
     ]
    }
   ],
   "source": [
    "index = similarities.MatrixSimilarity(lsi[corpus]) # transform corpus to LSI space and index it\n",
    "\n",
    "# save and load the index\n",
    "index.save('/tmp/deerwester.index')\n",
    "index = similarities.MatrixSimilarity.load('/tmp/deerwester.index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing queries\n",
    "To obtain similarities of our query document against the nine indexed documents.   \n",
    "Cosine measure returns similarities in the range <-1, 1> (the greater, the more similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.99809301), (1, 0.93748635), (2, 0.99844527), (3, 0.9865886), (4, 0.90755945), (5, -0.12416792), (6, -0.10639259), (7, -0.098794639), (8, 0.050041765)]\n"
     ]
    }
   ],
   "source": [
    "sims = index[vec_lsi] # perform a similarity query against the corpus\n",
    "print(list(enumerate(sims))) # print (document_number, document_similarity) 2-tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8, 0.99844527),\n",
       " (7, 0.99809301),\n",
       " (6, 0.9865886),\n",
       " (5, 0.93748635),\n",
       " (4, 0.90755945),\n",
       " (3, 0.050041765),\n",
       " (2, -0.098794639),\n",
       " (1, -0.10639259),\n",
       " (0, -0.12416792)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " sorted(enumerate(sims), key=lambda item: -item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
